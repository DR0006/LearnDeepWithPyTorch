{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPU details:\n",
      "    gpu_is_available      :  True\n",
      "    cuda_device_count     :  1\n",
      "    cuda_device_name      :  NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
      "    cuda_device_capability:  (8, 6)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def gpu_is_available():\n",
    "    print('\\nGPU details:')\n",
    "    print(f'    gpu_is_available      : ', torch.cuda.is_available())\n",
    "    print(f'    cuda_device_count     : ', torch.cuda.device_count())\n",
    "    print(f'    cuda_device_name      : ', torch.cuda.get_device_name())\n",
    "    print(f'    cuda_device_capability: ', torch.cuda.get_device_capability(0))\n",
    "\n",
    "\n",
    "gpu_is_available()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPU Memory details:\n",
      "    total_memory: 4095.5 MB\n",
      "    allocated_memory: 0.0 MB\n",
      "    reserved_memory: 0.0 MB\n"
     ]
    }
   ],
   "source": [
    "def gpu_memory_info():\n",
    "    if torch.cuda.is_available():\n",
    "        print('\\nGPU Memory details:')\n",
    "        device = torch.cuda.current_device()\n",
    "        mem_info = torch.cuda.get_device_properties(device)\n",
    "\n",
    "        print(f'    total_memory: {mem_info.total_memory / (1024 ** 2)} MB')\n",
    "        print(f'    allocated_memory: {torch.cuda.memory_allocated(device) / (1024 ** 2)} MB')\n",
    "        print(f'    reserved_memory: {torch.cuda.memory_reserved(device) / (1024 ** 2)} MB')\n",
    "\n",
    "gpu_memory_info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, pred_s = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(torch.Tensor(pred_s == labels)).item() / len(pred_s), dtype=torch.float32)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    \"\"\"评估模型在验证集上的性能\"\"\"\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "\n",
    "def get_default_device():\n",
    "    \"\"\"获取默认设备，如果有 GPU 则选择 GPU，否则选择 CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"将张量（或张量组成的列表/元组）移动到指定的设备\"\"\"\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "\n",
    "class DeviceDataLoader:\n",
    "    \"\"\"包装数据加载器，将数据移动到指定设备上\"\"\"\n",
    "\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"将数据移动到设备后，产生一个批次的数据\"\"\"\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"批次数量\"\"\"\n",
    "        return len(self.dl)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    @staticmethod\n",
    "    def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "        \"\"\"训练模型并在每个 epoch 结束后在验证集上评估性能\"\"\"\n",
    "        history = []\n",
    "        optimizer = opt_func(model.parameters(), lr, weight_decay=1e-5)\n",
    "        start_time = time.time()  # 记录开始时间\n",
    "\n",
    "        # 第一阶段：冻结层的初始训练\n",
    "        print(\"第一阶段训练\")\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            train_losses = []\n",
    "            for batch in train_loader:\n",
    "                loss = model.training_step(batch)\n",
    "                train_losses.append(loss)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            # 每个 epoch 结束后的验证阶段\n",
    "            result = evaluate(model, val_loader)\n",
    "            result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "            model.epoch_end(epoch, result)\n",
    "            history.append(result)\n",
    "\n",
    "            end_time = time.time()  # 记录每一轮的结束时间\n",
    "            epoch_time = end_time - start_time  # 计算每一轮的时间\n",
    "            print(f\"第 {epoch + 1} 轮训练时间: {epoch_time // 60} 分 {epoch_time % 60} 秒\")\n",
    "\n",
    "            # 更新最佳模型参数\n",
    "            if result['val_acc'] > model.best_accuracy:\n",
    "                model.best_accuracy = result['val_acc']\n",
    "                model.best_model_state = model.state_dict()\n",
    "\n",
    "        model.load_state_dict(model.best_model_state)\n",
    "        # 解冻层进行微调\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        # 第二阶段：使用较低的学习率进行微调\n",
    "        optimizer = opt_func(model.parameters(), lr=0.0001)\n",
    "        print(\"第二阶段微调\")\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            train_losses = []\n",
    "            for batch in train_loader:\n",
    "                loss = model.training_step(batch)\n",
    "                train_losses.append(loss)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            # 每个 epoch 结束后的验证阶段\n",
    "            result = evaluate(model, val_loader)\n",
    "            result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "            model.epoch_end(epoch, result)\n",
    "            history.append(result)\n",
    "\n",
    "            end_time = time.time()  # 记录每一轮的结束时间\n",
    "            epoch_time = end_time - start_time  # 计算每一轮的时间\n",
    "            print(f\"第 {epoch + 1} 轮训练时间: {epoch_time // 60} 分 {epoch_time % 60} 秒\")\n",
    "\n",
    "            # 更新最佳模型参数\n",
    "            if result['val_acc'] > model.best_accuracy:\n",
    "                model.best_accuracy = result['val_acc']\n",
    "                model.best_model_state = model.state_dict()\n",
    "\n",
    "        end_time = time.time()  # 记录结束时间\n",
    "        total_time = end_time - start_time  # 计算总时间\n",
    "        print(f\"训练总时间: {total_time // 60} 分 {total_time % 60} 秒\")\n",
    "\n",
    "        return history\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        \"\"\"\n",
    "        这里的 f.cross_entropy 会自动应用 softmax 激活函数，并计算交叉熵损失\n",
    "        :param batch:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        images, labels = batch\n",
    "        out = self(images)  # 生成预测\n",
    "        loss = f.cross_entropy(out, labels)  # 计算损失\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)  # 生成预测\n",
    "        loss = f.cross_entropy(out, labels)  # 计算损失\n",
    "        acc = accuracy(out, labels)  # 计算准确率\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "\n",
    "    @staticmethod\n",
    "    def validation_epoch_end(outputs):\n",
    "        # 将损失列表转换为张量并计算均值\n",
    "        batch_losses = torch.stack([x['val_loss'] for x in outputs])\n",
    "        epoch_loss = batch_losses.mean()\n",
    "\n",
    "        # 将准确率列表转换为张量并计算均值\n",
    "        batch_acc_s = torch.stack([x['val_acc'] for x in outputs])\n",
    "        epoch_acc = batch_acc_s.mean()\n",
    "\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "\n",
    "    @staticmethod\n",
    "    def epoch_end(epoch, result):\n",
    "        print(\n",
    "            f\"第 {epoch + 1} 轮: 训练损失: {result['train_loss']:.4f}, 验证损失: {result['val_loss']:.4f}, \"\n",
    "            f\"验证准确率: {result['val_acc']:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from torchvision.models import ResNet50_Weights\n",
    "\n",
    "\n",
    "# 预训练模型 ResNet-50\n",
    "class ResNet(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.best_accuracy = 0.0\n",
    "        self.best_model_state = None  # 最高测试集评分的参数副本\n",
    "        # 使用预训练模型 ResNet-50\n",
    "        self.network = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        # 修改模型的第一层，使其适应单通道输入\n",
    "        self.network.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        # 替换最后一层全连接层\n",
    "        num_ftrs = self.network.fc.in_features\n",
    "        # dataset2 demo2\n",
    "        self.network.fc = nn.Linear(num_ftrs, 10)  # 数字0-9\n",
    "\n",
    "    def forward(self, xb):\n",
    "        # 使用 sigmoid 函数处理输出\n",
    "        return torch.sigmoid(self.network(xb))\n",
    "\n",
    "    def save_model(self):\n",
    "        \"\"\"\n",
    "        保存模型\n",
    "        \"\"\"\n",
    "        # 转换百分比形式\n",
    "        accuracy_percent = f'{self.best_accuracy * 100:.2f}%'\n",
    "        # 保存最佳模型参数和整个模型\n",
    "        best_model_weights_filename = f'./model/{accuracy_percent}_model_weights.pth'\n",
    "        # best_model_filename = f'./model/{accuracy_percent}_entire_model.pth'\n",
    "        torch.save(self.best_model_state, best_model_weights_filename)\n",
    "        # torch.save(self, best_model_filename)\n",
    "\n",
    "    def load_model_dict(self, path):\n",
    "        \"\"\"\n",
    "        加载模型的权重\n",
    "        :param path: 路径\n",
    "        \"\"\"\n",
    "        self.load_state_dict(torch.load(path))\n",
    "        self.eval()  # 设置为评估模式"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@File  : config.py\n",
    "@author: FxDr\n",
    "@Time  : 2023/11/23 23:16\n",
    "@Description:\n",
    "\"\"\"\n",
    "import torch\n",
    "import torchvision.transforms as transforms  # transforms 模块包含用于图像预处理的各种转换操作\n",
    "\n",
    "# 训练参数\n",
    "num_epochs = 10  # 轮次\n",
    "opt_func = torch.optim.Adam  # 优化器\n",
    "lr = 5.5e-5  # 学习率\n",
    "batch_size = 64  # 批次大小\n",
    "# split_sizes = [55000, 500, 10000]  # 训练集验证集测试集图片数\n",
    "\n",
    "# 转换器，将数据转换为tensor并归一化\n",
    "# 数据增强防止过拟合\n",
    "transformers = {\n",
    "    # 原始处理\n",
    "    'original': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ]),\n",
    "    'demo1': transforms.Compose([\n",
    "        transforms.Resize((28, 28)),  # 其实不需要这一步，因为数据集已经是被处理好了的，都是28x28\n",
    "        # 随机图像亮度、对比度、饱和度\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        # 随机翻转\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(5),\n",
    "        # 随机放射变化\n",
    "        transforms.RandomAffine(degrees=11, translate=(0.1, 0.1), scale=(0.8, 0.8)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ]),\n",
    "\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset MNIST\n    Number of datapoints: 60000\n    Root location: ../data\n    Split: Train\n    StandardTransform\nTransform: Compose(\n               Resize(size=(28, 28), interpolation=bilinear, max_size=None, antialias=warn)\n               ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=(0.8, 1.2), hue=None)\n               RandomRotation(degrees=[-5.0, 5.0], interpolation=nearest, expand=False, fill=0)\n               RandomAffine(degrees=[-11.0, 11.0], translate=(0.1, 0.1), scale=(0.8, 0.8))\n               ToTensor()\n               Normalize(mean=(0.5,), std=(0.5,))\n           )"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "train_dataset = MNIST(root='../data', train=True, transform=transformers['demo1'], download=False)\n",
    "test_dataset = MNIST(root='../data', train=False, transform=transformers['demo1'], download=False)  # 测试集\n",
    "train_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# 划分训练集为训练集和验证集\n",
    "train_dataset, val_dataset = random_split(train_dataset, [55000, 5000])\n",
    "\n",
    "# 数据加载器\n",
    "# batch_size*2 验证集的批量大小是训练集的两倍\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size * 2, shuffle=False, num_workers=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x1bcf9f032e0>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.family'] = 'Microsoft YaHei'\n",
    "\n",
    "image, label = train_dataset[0]\n",
    "plt.title(label)\n",
    "plt.imshow(image.squeeze().numpy(), cmap='gray')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1500x300 with 10 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_samples = {i: None for i in range(10)}\n",
    "\n",
    "# Find one sample from each class\n",
    "for data, target in train_dataset:\n",
    "    if class_samples[target] is None:\n",
    "        class_samples[target] = data\n",
    "    if all(sample is not None for sample in class_samples.values()):\n",
    "        break\n",
    "\n",
    "# Visualize the samples\n",
    "fig, axs = plt.subplots(1, 10, figsize=(15, 3))\n",
    "for i, (class_idx, sample) in enumerate(class_samples.items()):\n",
    "    axs[i].imshow(sample.squeeze().numpy(), cmap='gray')\n",
    "    axs[i].axis('off')\n",
    "    axs[i].set_title(f'Class {class_idx}')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": "ResNet(\n  (network): ResNet(\n    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (fc): Linear(in_features=2048, out_features=10, bias=True)\n  )\n)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建 ResNet 模型实例\n",
    "model = ResNet()\n",
    "\n",
    "# 移动到GPU\n",
    "device = get_default_device()\n",
    "print(\"Using device:{}\".format(device))\n",
    "train_dl = DeviceDataLoader(train_loader, device)\n",
    "val_dl = DeviceDataLoader(val_loader, device)\n",
    "to_device(model, device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " # training\n",
    "history = model.fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 中文绘制\n",
    "plt.rcParams['font.family'] = 'Microsoft YaHei'\n",
    "\n",
    "\n",
    "def plot_accuracies(history):\n",
    "    \"\"\"绘制准确率曲线\"\"\"\n",
    "    accuracies = [x['val_acc'] for x in history]\n",
    "    plt.plot(accuracies, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy vs. No. of epochs')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_losses(history):\n",
    "    \"\"\"绘制损失曲线\"\"\"\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 可视化损失和准确率\n",
    "plot_accuracies(history)\n",
    "plot_losses(history)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "# model.save_model()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
