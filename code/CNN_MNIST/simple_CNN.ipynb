{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 简单的卷积神经网络\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 设置训练参数\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "\n",
    "# 数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# 加载MNIST数据集\n",
    "train_dataset = datasets.MNIST(root='../../data', train=True, transform=transform, download=False)\n",
    "test_dataset = datasets.MNIST(root='../../data', train=False, transform=transform, download=False)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "SimpleCNN(\n  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (relu1): ReLU()\n  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (relu2): ReLU()\n  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n  (relu3): ReLU()\n  (fc2): Linear(in_features=128, out_features=10, bias=True)\n)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化模型、损失函数和优化器\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.0981, Test Accuracy: 0.9866\n",
      "Epoch 2/10, Loss: 0.1356, Test Accuracy: 0.9883\n",
      "Epoch 3/10, Loss: 0.0018, Test Accuracy: 0.9903\n",
      "Epoch 4/10, Loss: 0.0493, Test Accuracy: 0.9902\n",
      "Epoch 5/10, Loss: 0.0057, Test Accuracy: 0.9904\n",
      "Epoch 6/10, Loss: 0.0019, Test Accuracy: 0.9884\n",
      "Epoch 7/10, Loss: 0.0011, Test Accuracy: 0.9915\n",
      "Epoch 8/10, Loss: 0.0032, Test Accuracy: 0.9894\n",
      "Epoch 9/10, Loss: 0.0004, Test Accuracy: 0.9896\n",
      "Epoch 10/10, Loss: 0.0002, Test Accuracy: 0.9903\n"
     ]
    }
   ],
   "source": [
    "loss = None\n",
    "# 训练模型\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 在测试集上进行评估\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += torch.Tensor((predicted == labels)).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}, Test Accuracy: {accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "    \"\"\"\n",
    "    保存模型\n",
    "    \"\"\"\n",
    "    # 转换百分比形式\n",
    "    accuracy_percent = f'{accuracy * 100:.2f}%'\n",
    "    model_weights_filename = f'./{accuracy_percent}_simple_model_weights.pth'\n",
    "    torch.save(model.state_dict(), model_weights_filename)\n",
    "\n",
    "# save_model(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:cuda\n",
      "Predicted digit: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# 设备配置\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:{}\".format(device))\n",
    "\n",
    "# 转换器，将数据转换为tensor并归一化\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# 加载模型\n",
    "model = SimpleCNN().to(device)\n",
    "model.load_state_dict(torch.load('./99.03%_simple_model_weights.pth', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# 加载图片\n",
    "image_path = r'X:\\Coding\\Github\\LearnDeepWithPyTorch\\code\\data\\images\\test\\4_826.png'\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# 处理图片\n",
    "image = transform(image).unsqueeze(0).to(device)  # 添加一个批次维度并发送到设备\n",
    "\n",
    "# 预测\n",
    "with torch.no_grad():\n",
    "    output = model(image)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "print(f'Predicted digit: {predicted.item()}')\n",
    "\n",
    "# 可视化图片\n",
    "plt.imshow(image.cpu().squeeze(), cmap='gray')  # 如果需要在CPU上运行，确保调用.cpu()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
