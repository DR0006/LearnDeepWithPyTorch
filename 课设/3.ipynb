{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "{'airplane': 0,\n",
    " 'automobile': 1,\n",
    " 'bird': 2,\n",
    " 'cat': 3,\n",
    " 'deer': 4,\n",
    " 'dog': 5,\n",
    " 'frog': 6,\n",
    " 'horse': 7,\n",
    " 'ship': 8,\n",
    " 'truck': 9}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "Compose(\n    Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)\n    RandomHorizontalFlip(p=0.1)\n    RandomRotation(degrees=[-20.0, 20.0], interpolation=nearest, expand=False, fill=0)\n    ToTensor()\n    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "# 图像增广\n",
    "IMAGE_SIZE = 32\n",
    "\n",
    "mean, std = [0.4914, 0.4822, 0.4465], [0.247, 0.243, 0.261]\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    # 在高度和宽度上将图像RESIZE\n",
    "    torchvision.transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),  # Resize\n",
    "    torchvision.transforms.RandomHorizontalFlip(0.1),\n",
    "    torchvision.transforms.RandomRotation(20),\n",
    "    # torchvision.transforms.ColorJitter(brightness=0.1,  #随机颜色抖动\n",
    "    #                                    contrast=0.1,\n",
    "    #                                    saturation=0.1),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    # 标准化图像的每个通道\n",
    "    torchvision.transforms.Normalize(mean, std)])\n",
    "\n",
    "# 在测试期间，只对图像执行标准化，以消除评估结果中的随机性。\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean, std)])\n",
    "\n",
    "transform_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# load and transform\n",
    "train_dataset = datasets.CIFAR10(root='../data', train=True, download=False, transform=transform_train)\n",
    "validation_dataset = datasets.CIFAR10(root='../data', train=False, download=False, transform=transform_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据集:\n",
      "批次数量: 500\n",
      "总样本数量: 50000\n",
      "一个批次的数据形状: torch.Size([100, 3, 32, 32])\n",
      "一个批次的标签形状: torch.Size([100])\n",
      "\n",
      "验证数据集:\n",
      "批次数量: 100\n",
      "总样本数量: 10000\n",
      "一个批次的数据形状: torch.Size([100, 3, 32, 32])\n",
      "一个批次的标签形状: torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# 训练数据集信息\n",
    "print(\"训练数据集:\")\n",
    "print(\"批次数量:\", len(train_loader))\n",
    "print(\"总样本数量:\", len(train_loader.dataset))\n",
    "print(\"一个批次的数据形状:\", next(iter(train_loader))[0].shape)\n",
    "print(\"一个批次的标签形状:\", next(iter(train_loader))[1].shape)\n",
    "\n",
    "# 验证数据集信息\n",
    "print(\"\\n验证数据集:\")\n",
    "print(\"批次数量:\", len(validation_loader))\n",
    "print(\"总样本数量:\", len(validation_loader.dataset))\n",
    "print(\"一个批次的数据形状:\", next(iter(validation_loader))[0].shape)\n",
    "print(\"一个批次的标签形状:\", next(iter(validation_loader))[1].shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.rcParams['font.family'] = 'Microsoft YaHei'\n",
    "\n",
    "\n",
    "def show_data(img):\n",
    "    try:\n",
    "        plt.imshow(img[0])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    print(img[0].shape, img[0].permute(1, 2, 0).shape)\n",
    "    plt.imshow(img[0].permute(1, 2, 0))\n",
    "    plt.title('实际标签: ' + str(img[1]))\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid shape (3, 32, 32) for image data\n",
      "torch.Size([3, 32, 32]) torch.Size([32, 32, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAG1CAYAAAAm1fnEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAq/0lEQVR4nO3deXxU1f3/8fcMkUkGyEAIRYhJCYsSvsgSwEhrQaU/ZVPEqlgRqm2VsBXRhxZERBaLLF+1igt8i1iXquBacStKQFExBEykgA2WCAm4xAAzLCaE5Pz+6IOpYxLIhMmZyeT1fDzu48Hce+bcz81N5s2ZuXOuwxhjBACARc5wFwAAaHwIHwCAdYQPAMA6wgcAYB3hAwCwjvABAFhH+AAArCN8AADWET6IekePHtU///lPq/vcvn27ysrK6vx8Y4zuvPNOrVmzptrtf/rTn7R69eo69w+Em4MZDhDtxo8fr1deeUX//Oc/lZiYWGO7nTt3av369QHrLrroInXq1CnofcbGxionJ0fdu3eXJH366acnDaP4+Hh169bN/3jVqlW64YYb9MUXX6hdu3YBbXNycpSRkaHt27frnHPOCbq2E5YuXaq//OUvys/PV2xsrH7+859rwYIF6tKlS537BGqL8EHU+/rrr9WtWzf9+c9/1pgxY2ps9+STTyozM1O9evWSJH3yySf629/+pttvv1179+6t8XnNmjXT4cOHA9b9OHx69Oihffv21djHz3/+c7322muSpIqKCnXv3l2ff/55lXYzZsxQTk6O3nnnnWr7KSws1FlnnVXjfn4oMTFRQ4YMUVpamnbv3q2nnnpKrVu3Vl5enlq3bl2rPoC6igl3AUAo5Obmqnfv3idtM3bsWI0dO7bK+mHDhvnfwjrrrLO0ceNG/etf/1LXrl3Vs2dPrV+/XuXl5TX263Se+t3rzz777JRtTli4cKGOHTumgoICHTp0SK1atfJvW7lypdauXastW7aoWbNmio2NDdj/j0dJJ5ObmxsQVOedd55+//vfa/Xq1frNb35T636AuiB8EFXWrVuntm3bqry8XGeccUbAtrKyMsXExKhJkyb+dffcc0+VUYskZWVlqV27dgFvhZ3Kgw8+qKlTp/ofn3vuuZKkFStW6IYbbqhVH2vXrtXMmTO1evVq7dy5U+PGjVNOTo4SEhJ06NAhdenSRXfffbd69+6t3/72t5Kk5cuXy+Fw1LrOE348Qjr//PMlSSUlJUH3BQSLCw4QFZo2baqkpCSdc845atq0qX75y19q1apVSk5OVteuXdW1a1f94he/0Pvvv+9/3LVrV6Wmplb7OdDatWt10UUXBVXDb3/7WxUUFOiNN96QJL3zzjsqKCjQVVddVes+FixYoIkTJ2rw4MEaMGCAEhISNGPGDBUUFKhv3766/PLL/fWOGzdOL7/8subNmxfQx5o1a+TxePTXv/41qPpzc3Ml/WcEBNQ3Rj6ICt26dVNRUZH/8eLFi3X77bdr6dKlWrZsmYYOHSpjjGJiAn/l58+fX6WviooKvfvuu/rf//1f7dmzR0ePHj3l/l0ul1JTUxUfH6+///3vkqT27durQ4cO+uqrrwJqq0liYqKeeuopJSQk+Pt85ZVXlJOTo5/97Gfq16+fpk2bpszMTJWUlOjOO+/U6tWrFR8fH9DPt99+K5/Pd9LPmCSpvLxce/fu1f79+/XRRx9p1qxZuummm3TBBRecslbgtBkgimzfvt1s27bNGGPM/v37zY033mjef/99Y4wxMTEx5umnn67xuStWrDCdOnUymzZtMpLMjh07zMCBA42kUy7/8z//4+/nF7/4hZFkXnvtNXP48GEzevToWvUxa9asgHqOHDli/vjHP5omTZqY22+/3VRUVBhjjFm9erWJj483AwcONPn5+dUey969e0/5s9q6dWvA/m+++Wbj8/lO+TwgFAgfRJVp06YZp9NpxowZY/7973/71x89etRIMq+++mqNzz0RPqWlpebcc881EyZMqNKmsLDQH0zV+eKLL0zbtm1N06ZNTXp6ujnvvPPMgQMHAtp8/PHHRpIpLy+vto+KigrzzDPPmLPOOss0a9bMPP7442bnzp0Byz/+8Q+TkpJiYmJizNixY83mzZtr8dMJ5PP5zCuvvGKeeOIJc9ttt5mEhASTmppaY6ABoUT4IOq89dZbplu3bqZp06Zm9+7dxhhj8vPzjSTzySef1Pi8E+FjjDFr1641TZo0Mbt27TLGGFNUVGSMqRo++/fvD+hj0qRJJjMz07hcLvPRRx+Z9PR0c//995tvv/3W/Otf/zLGBIbPt99+a7788kv/8//v//7PdOrUybhcLnP77beba6+9tsaRUpMmTczy5ctNSkqKkWTOPvtsU1JSUuefW35+vmnevLkZNmxYnfsAaovwQVQ6fvy4effdd/2PX3zxRSOpyijkh34YPsYY06lTJ/PAAw+YY8eOmbZt25onnngiIHyWLVtmunTp4n87rKCgwLhcLrNp0ybjcrnM1q1bzcGDB01lZaW56667TEpKiqmoqAgIn8GDB5uRI0f69/nQQw+ZyZMnm8LCwir1rVy5ssrbacXFxaa0tNSsWrXKPP7443X9cfkNGTLExMfHn3Y/wKlwtRuiwrx58+RwOPxLTEyMfvnLX/ofn7jirFWrVgHtTixffvlllT7POecc7du3T6+//roOHTqkK6+8MmD7FVdcob1792rVqlWSpFdffVU/+9nP1LdvX38bj8ej0tJSLV26VFOmTKnynaBbbrlFr776qv97QJMnT9ZDDz2kjz76SKNHjw5o++CDD+q5554LWHf11VcrMzNTV111lcaNG1e3H94PVFRUBFyKDtQXwgdRYfz48dqxY0e1y6xZsyRJs2bNqrFNUlJSQH+VlZXavXu3mjVrpqVLl2rUqFHyeDwBbdq0aaPf//73/ivmLr/8ci1atKhKbcuXL9exY8d00003Vdl26aWXqmfPnpo7d27A+n79+unFF19UVlaWf92vfvUrvfLKK/7H69at04YNG3TrrbdW6fdUV7pt27ZN33//fcC63NxcrV+/XoMGDTrpc4GQCPfQC6gv5eXl5r777jNNmjQxXbp0MU6n04wYMcJ88MEH1bZfsWKF6dixo+nRo4dp27atcbvd5sknnzQOh8Pk5eUZY6p+5rN7924TExNjXn/99YC+Trzt9v3335v27dubu+++27/txxcc/PWvfzVOp7PKB/2TJ082PXv29L+tt3XrVuN0Ok1xcbGpqKgw6enp5rbbbqtyHM8++6yRZO67774afzYPPPCAadeunfnDH/5gFixYYG666SYTFxdnWrdubXbu3HmqHy1w2ggfRJ39+/ebRx55xHTp0sW4XC6zePFiY4wx2dnZZuTIkcbhcJiMjAzz4osv+l/YjfnvZz5r1qwxTz75pCkqKjJDhgwxl112mb9NdVe7XXfddaZ///4BNZwIn3nz5pmEhARz8OBB/7YPP/zQSDLHjx83xhhTWlpq2rRpY26++eaAPr755hszd+5cU1pa6l+3Z88eY4wxy5YtM8nJyebw4cNVjv/tt982LVq0MCtWrKjxZ7Rjxw5zzTXXmKSkJHPGGWeYdu3amRtuuCHg4gegPhE+iArZ2dlmzpw55qKLLjJnnHGGiYuLq/HFdPv27ebXv/61cTqdplOnTubRRx81xlS94MAYYx588EGTk5NjPv74Y7N161Zz7733Gknm66+/9rfZtm2befPNNwOedyJ8du/ebd5++21z8OBBs379epOXl2emTp1qWrZsGdD+rbfeMnv27DFZWVm1+k5QdcuoUaNC9eME6h0zHCAq7NmzR4sWLdKFF16ohx9+WKNGjVLLli2rbZuWlqa//e1vuuuuuzR79mxt3ry5xn6nTJkiSerdu7dyc3Plcrk0efJktW3b1t+mW7duNc4Bl5KSopSUFH311Ve68MILZYxRfHx8lSlxBg8eLElq3bq1duzYEcyh+/14pgMgknFLBUSN48ePV5k+pzaMMbWamLOiokJOp7NOk3gGuy8g2hE+AADruNQaAGAd4QMAsI7wAQBYF1FXu1VWVmrfvn1q0aIFH8oCQANkjNGhQ4fUvn37k95iPqLCZ9++fUpOTg53GQCA01RYWFjlVu0/FPLwMcZozpw5Wrp0qbxery699FItW7as2lsV/1iLFi2C3p/X661LmSE3f+KsoNpffc3gWrftPLB/sOUAUe3H8+wh8pzq9Tzk4bNo0SI99NBDevLJJ9W6dWv97ne/029+8xv/fe1Ppi5vtUXKF+tim7qCat+8WbNat42UYwSA2jrV63lIw6eyslKLFi3SzJkzddlll0mS7r//fg0dOlQFBQVKTU0N5e4AAA1USMNn69at+u677/xThUjShRdeKKfTqY0bN1YJn7KyMpWVlfkf+3y+UJYDAIhQIb3UeteuXZIUEDJxcXFq06aN9u7dW6X9/Pnz5fF4/AsXGwBA4xDS8Dl8+LCcTqdcrsDPP9xut0pLS6u0nz59urxer38pLCwMZTkAgAgV0rfdXC6XKisrq0zwWFpaKrfbXW37HwcVACD6hXTkc+JWxEVFRf51ZWVlKi4uVseOHUO5KwBAAxbS8ElPT1dcXJzWrFnjX7d+/XpJ0oABA0K5KwBAAxbSt93i4uI0fvx43X333UpJSVHz5s11yy23KDMzUwkJCaHcFQCgAQv5l0z/9Kc/6fvvv9c111yjJk2a6Prrr9eiRYtCvZuIU/r1N0G1P2fQL2rdNqJuuVR8NKjm2f/IqnXbA0GWcunoYUE+A9Eiov4mEMDn89VqBoqQh4/L5dKjjz6qRx99NNRdAwCiBLdUAABYR/gAAKwjfAAA1hE+AADrCB8AgHWEDwDAOsIHAGAd4QMAsI7wAQBYF/IZDhqr/9e/X1Dt73vzyVq3PdW90KPFPddMDKo90+sADRcjHwCAdYQPAMA6wgcAYB3hAwCwjvABAFhH+AAArCN8AADWET4AAOsIHwCAdYQPAMA6wgcAYB1zu4XIxUMvDu4JM+unjoZszOjLwl0CAEsY+QAArCN8AADWET4AAOsIHwCAdYQPAMA6wgcAYB3hAwCwjvABAFhH+AAArCN8AADWMb1OqKR3DXcFDV7Hyy8NdwkALGHkAwCwjvABAFhH+AAArCN8AADWET4AAOsIHwCAdYQPAMA6wgcAYB3hAwCwjvABAFhH+AAArCN8AADWET4AAOtCGj4rVqyQw+EIWCZNmhTKXQAAokBIb6lQUlKijIwMPfPMM/51LVu2DOUuAABRIKThs3//fiUlJalz586h7BYAEGVCHj6JiYm1bl9WVqaysjL/Y5/PF8pyAAARKqSf+ZSUlGj58uVq0aKFevTooYULF6q8vLzG9vPnz5fH4/EvycnJoSwHABChHMYYE6rOtm/frmPHjqmsrEzvvfee5syZo0mTJmnx4sXVtq9u5BNsAIWwfKscDke4S4g4DfVcAvgvn88nj8cjr9er+Pj4GtuFNHx+bO7cuVqwYIEOHTpUqxfbE0UHo6G+YBE+VTXUcwngv2obPvX6PZ/09HQdOXJEJSUl9bkbAEADU6/hk52drVatWikhIaE+dwMAaGBCerXb5MmTNWzYMLVr107vvvuuFi5cqNmzZ8vpjP6JFN5f+lK4SwCABiOk4XPkyBGNHj1apaWlOvvss7Vs2TKNGTMmlLsAAESBkIbPE088EcruAABRKvrfDwMARBzCBwBgHeEDALCO8AEAWEf4AACsI3wAANYRPgAA6wgfAIB1hA8AwLqQznDQmA3MvCrcJTR4S+96IKj24+ZNradKANQ3Rj4AAOsIHwCAdYQPAMA6wgcAYB3hAwCwjvABAFhH+AAArCN8AADWET4AAOsIHwCAdQ5jjAl3ESf4fD55PJ6gnhMp5TscjnCX0OhEyrkH8F8nXse9Xq/i4+NrbMfIBwBgHeEDALCO8AEAWEf4AACsI3wAANYRPgAA6wgfAIB1hA8AwDrCBwBgHeEDALCO8AEAWBcT7gKqc6o5gWwZnJwR7hIaFeZqAxoPRj4AAOsIHwCAdYQPAMA6wgcAYB3hAwCwjvABAFhH+AAArCN8AADWET4AAOsIHwCAdYQPAMC6iJzbLVL0H9C71m3f+Vt2PVYCoDFq5nDUuu3RIPsO91yKjHwAANbVKXy2bt2qPn36aMOGDQHrX3rpJaWlpSk2Nlb9+vXT5s2bQ1IkACC6BBU+W7Zs0ahRo5SRkaEtW7YEbPv444917bXXaty4cfrkk0+UnJysoUOH6vDhwyEtGADQ8AUVPi+//LKaNm2q1atXV9m2aNEiDRs2TLfccot69uypJ554Ql6vV6tWrQpZsQCA6BBU+MydO1dPP/20OnbsWGVbVlaWBg8e7H/csmVLpaena+PGjTX2V1ZWJp/PF7AAAKJfUOHjqOHKiwMHDujgwYNKTU0NWJ+SkqK9e/fW2N/8+fPl8Xj8S3JycjDlAAAaqJBc7Xbicx232x2w3u12q7S0tMbnTZ8+XV6v178UFhaGohwAQIQLyfd8XC6XJOnYsWMB60tLS6sE0o+fd+K5AIDGIyQjn8TERLlcriojl8LCwmo/HwIANG4hCR+n06n+/ftrzZo1/nVer1ebN2/WoEGDQrELAEAUCdn0OlOnTtWVV16pAQMG6Pzzz9ecOXN09tlna+jQoaHahXVd0zqFu4RGpaYLWsKhj2p/7nPMF/VYCaJJd0fnoNoHO2VOMPq26lPrtjkHQj9hQMim17n88sv15z//WXPmzFH//v1VVlam1atXq0mTJqHaBQAgStRp5NOhQ4dqJ6WbOHGiJk6ceNpFAQCiGxOLAgCsI3wAANYRPgAA6wgfAIB1hA8AwDrCBwBgHeEDALCO8AEAWEf4AACsC9ncbtHo66Kab4SH6LZZ/65120iak25g8x5BtZ885fe1bnvZ0MGnbvQDTX/WJaj2jcG2IH6v6tvmg1vCun9GPgAA6wgfAIB1hA8AwDrCBwBgHeEDALCO8AEAWEf4AACsI3wAANYRPgAA6wgfAIB1TK9zEllrN4W7BCAo6w9/Flz7e/9Q+8b3BldLUhBti4wJrvMIMnVEZrhLqJNX//JqWPfPyAcAYB3hAwCwjvABAFhH+AAArCN8AADWET4AAOsIHwCAdYQPAMA6wgcAYB3hAwCwjvABAFjnMCZyJlXy+XzyeDzyer2Kj48Pdzlq5jij1m2P6ng9VgLghyLoZUsOhyPcJdRJff0Ma/s6zsgHAGAd4QMAsI7wAQBYR/gAAKwjfAAA1hE+AADrCB8AgHWEDwDAOsIHAGAd4QMAsC4m3AVEMqbMARofD9PlWMHIBwBgXZ3CZ+vWrerTp482bNjgX1dQUCCHwxGwdO/ePWSFAgCiR1Bvu23ZskULFizQ66+/ru+//z5gW0lJiZxOpz7//HP/LK8ulyt0lQIAokZQ4fPyyy+radOmWr16tQYNGhSwbf/+/WrZsqW6dOkS0gIBANEnqPCZO3euHA6Hvvzyyyrb9u/fr8TExFDVBQCIYkF95nOymyaVlJRo586diouLU+fOnZWZmani4uKT9ldWViafzxewAACiX8iudhsxYoQ2bdqkjz76SHfddZfeeOMNXXbZZaqoqKjxOfPnz5fH4/EvycnJoSoHABDB6nQb7S+//FKpqan64IMPdMEFF1Tb5oMPPtCAAQOUnZ2tfv36VdumrKxMZWVl/sc+n0/JyckRcxvthnp7XCDa1ed3WoL9nk+kvF8TKd/zCftttNPT0yVJu3fvrrGNy+VSfHx8wAIAiH71Fj7Z2dmSpM6dO9fXLgAADVTIptdZvHix2rdvr+7du2v79u264447NGTIEPXq1StUuwAARImQhY/b7dYdd9yh7777TikpKRo7dqzuuuuuUHUPAH7BfB575LP8oPqOlM9wJOmeiQvDXUK9qVP4dOjQocqHWxMmTNCECRNCUhQAILoxsSgAwDrCBwBgHeEDALCO8AEAWEf4AACsI3wAANYRPgAA6wgfAIB1hA8AwDrCBwBgXZ3u51NfansfCFuaBDF/VGU91gGgcYqgl+daC/v9fAAAqAnhAwCwjvABAFhH+AAArCN8AADWET4AAOsIHwCAdYQPAMA6wgcAYB3hAwCwLibcBUSyW4dOrHXbxW8+Uo+VAIgGu7d7w11CxGDkAwCwjvABAFhH+AAArCN8AADWET4AAOsIHwCAdYQPAMA6wgcAYB3hAwCwjvABAFhH+AAArHMYY0y4izjB5/PJ4/HI6/UqPj4+3OUExeFwhLsEABEugl5u601tX8cZ+QAArCN8AADWET4AAOsIHwCAdYQPAMA6wgcAYB3hAwCwjvABAFhH+AAArCN8AADWxYS7AABoyAZ2GRnuEhokRj4AAOuCDp+8vDxdcsklcrvdOvPMM3XjjTeqpKTEv/2xxx5Tamqq4uLidPHFF2vXrl0hLRgA0PAFHT7jx4/XhRdeqI0bN2r58uVav369xo4dK0lauXKlpk6dqjlz5mjDhg0qLy/XiBEjVFlZGfLCAQANV9Cf+Tz//PNKSUmRJPXo0UNer1djxozR0aNHdd999ykzM1NjxoyRJC1btkzdunXT+vXrddFFF4W2cgBAgxX0yOdE8JwQGxuryspKHTx4UJ9++qkGDx7s35aWlqZ27dpp48aN1fZVVlYmn88XsAAAot9pXXBgjNHy5cuVkZGhb775RpKUmpoa0CYlJUV79+6t9vnz58+Xx+PxL8nJyadTDgCggahz+JSXl+vmm29WVlaWlixZosOHD0uS3G53QDu3263S0tJq+5g+fbq8Xq9/KSwsrGs5AIAGpE7f8ykqKtKoUaNUUFCgdevWqW/fvsrOzpYkHTt2LKBtaWlplUA6weVyyeVy1aUEAEADFvTIJz8/XxkZGYqPj1deXp7OO+88SVJSUpIkVRm9FBYWqmPHjiEoFQAQLYIOn+uuu04DBw7UG2+8oTZt2vjXJyUlqUOHDlqzZo1/XX5+voqKijRo0KDQVAsAiApBve22c+dObd68WdOmTavy5dE2bdro1ltv1fTp09WrVy+lpqZq6tSpGj58uM4999yQFg0AaNiCCp+vvvpKknT11VdX2fbwww9r0qRJKi4u1oQJE1RaWqoRI0ZoyZIloakUACLQuvyXw11Cg+QwxphwF3GCz+eTx+OR1+tVfHx8uMsJisPhCHcJAMIggl5CI0JtX8eZWBQAYB3hAwCwjvABAFhH+AAArCN8AADWET4AAOsIHwCAdYQPAMA6wgcAYF2dbqnQUDVzxAXV/qiqvw8RgOi1eOIj4S6hUWDkAwCwjvABAFhH+AAArCN8AADWET4AAOsIHwCAdYQPAMA6wgcAYB3hAwCwjvABAFhH+AAArGtUc7sxVxvQ+Gx+bUdQ7dMv71pPlTRcDocj5H0y8gEAWEf4AACsI3wAANYRPgAA6wgfAIB1hA8AwDrCBwBgHeEDALCO8AEAWEf4AACsa/DT69THtA8AoseOnf8Kqn26mF7HBkY+AADrCB8AgHWEDwDAOsIHAGAd4QMAsI7wAQBYR/gAAKwjfAAA1hE+AADrCB8AgHWEDwDAuoic283j8YS7BABR4rsD34S7BFSDkQ8AwLqgwycvL0+XXHKJ3G63zjzzTN14440qKSmRJGVlZcnhcAQsw4cPD3nRAICGLei33caPH6/hw4dr8eLFKiws1OTJkzV27Fi98cYbKikpUVJSktatW+dv36xZs1DWCwCIAkGHz/PPP6+UlBRJUo8ePeT1ejVmzBgdPXpU+/fvV9u2bdW5c+eQFwoAiB5Bh8+J4DkhNjZWlZWVkqT9+/crMTGx1n2VlZWprKzM/9jn8wVbDgCgATqtCw6MMVq+fLkyMjLkdrtVUlKid999V82aNVNaWpqmTZumw4cP1/j8+fPny+Px+Jfk5OTTKQcA0EDUOXzKy8t18803KysrS0uWLJEkZWZmKicnR++//74mTpyoZcuW6YYbbqixj+nTp8vr9fqXwsLCupYDAGhA6vQ9n6KiIo0aNUoFBQVat26d+vbtK0nq1KmTv02fPn3k8Xg0duxYFRcXq02bNlX6cblccrlcdSwdANBQBT3yyc/PV0ZGhuLj45WXl6fzzjuvxrbp6emSpN27d9e9QgBA1Al65HPddddp4MCBeuaZZ+R0njy7srOz5XQ6lZqaWucCAQDRJ6jw2blzpzZv3qxp06Zp165dAdvatGmjhQsXql+/furYsaM++eQT/fGPf9S4cePUunXrkBYNAGjYggqfr776SpJ09dVXV9n28MMPy+FwaNy4cfL5fOrYsaNmzpypP/zhD6GpNAz+8virtW77u3Ej6q+QeuRwOMJdghV5z3waVPseo3vVuu1r81YG1fcVM0cF1R6np+u53cJdAqoRVPgMGDBAxpiTtpk3b95pFQQAiH5MLAoAsI7wAQBYR/gAAKwjfAAA1hE+AADrCB8AgHWEDwDAOsIHAGAd4QMAsM5hTjVlgUU+n08ej6fe+o+gQ40YLy0NbmqYqzLrb2qYpkG2L2ug57OxTGkUKfi7P311+Z31er2Kj4+vcTsjHwCAdYQPAMA6wgcAYB3hAwCwjvABAFhH+AAArCN8AADWET4AAOsIHwCAdYQPAMA6wgcAYF1MuAuozlfbChXfouY5gX7InVy7dqjer8ZdE9wTgpzbbfNf3q512/TfXRpcLWi0Hr/t/nCXgNPEyAcAYB3hAwCwjvABAFhH+AAArCN8AADWET4AAOsIHwCAdYQPAMA6wgcAYB3hAwCwzmGMMeEu4gSfzyePxyOv16v4eKbNQXRacMusoNp3iG1Z67axsa6g+r5i9sSg2keKCHrZahQcDkfQzznV6zgjHwCAdYQPAMA6wgcAYB3hAwCwjvABAFhH+AAArCN8AADWET4AAOsIHwCAdYQPAMA6wgcAYF1MuAsAGps/Pji73vre8/7nwT2h/koJyu/6DQl3CbCMkQ8AwLqgw+eFF15Qz5495Xa7lZKSonnz5gXMMPvYY48pNTVVcXFxuvjii7Vr166QFgwAaPiCDp/PP/9c06dP18aNGzVjxgzdc889Wrp0qSRp5cqVmjp1qubMmaMNGzaovLxcI0aMUGVlZcgLBwA0XKd9P59hw4bJ5XLp5ZdfVnp6ugYMGKAHH3xQkrRjxw5169ZNa9eu1UUXXXTKvrifD3B6gv3M56cD0+qpkuAE+5nPX7LfrKdKUJ2IvJ9PZWWlWrdurYMHD+rTTz/V4MGD/dvS0tLUrl07bdy4sdrnlpWVyefzBSwAgOhX56vdjhw5oueff14bN27U+vXrVVBQIElKTU0NaJeSkqK9e/dW28f8+fM1e3aEXG4DALCmTiOf2NhYNW/eXFOnTtWSJUvUo0cPHT58WJLkdrsD2rrdbpWWllbbz/Tp0+X1ev1LYWFhXcoBADQwdRr55Obmyuv1KicnR1OmTNG2bdt0xRVXSJKOHTsW0La0tLRKIJ3gcrnkcgV3z3kAQMNXp/Dp2rWrJCkjI0Nut1s33XSTJk6cKEkqLCxUp06d/G0LCwt1zTXXhKBUAEC0OO0LDmJiYmSMkcfjUYcOHbRmzRr/tvz8fBUVFWnQoEGnuxsAQBQJauTj8/k0adIkXX/99WrXrp3y8vJ0xx136Ne//rWaN2+uW2+9VdOnT1evXr2UmpqqqVOnavjw4Tr33HODKsrj8QTVHvac5pX5qGcpA7qGuwQ/fldwMkGFT2xsrMrLyzV27Fh5vV799Kc/1eTJk3XbbbdJkiZNmqTi4mJNmDBBpaWlGjFihJYsWVIvhQMAGq7T/pJpKJ34kikiVwT9uiAE6vLlwdridyV6ROSXTAEACBbhAwCwjvABAFhH+AAArCN8AADWET4AAOsIHwCAdYQPAMC6Ot/Ppz7wpbTIxw3/UFv8rjRup3o9j6jwOXToULhLwCkwAwVqi9+Vxu3QoUMn/R2IqOl1KisrtW/fPrVo0SJgOgefz6fk5GQVFhaedLqGhq4xHGdjOEaJ44w2jeE4Q3WMxhgdOnRI7du3l9NZ8yc7ETXycTqdOuuss2rcHh8fH7Un/ocaw3E2hmOUOM5o0xiOMxTHWJtRLxccAACsI3wAANY1iPBxuVyaNWuWXC5XuEupV43hOBvDMUocZ7RpDMdp+xgj6oIDAEDj0CBGPgCA6EL4AACsI3wAANYRPgAA6wgfAIB1ER0+xhjNnj1b7du3V7NmzXTllVfqu+++C3dZIbdixQo5HI6AZdKkSeEuK2S2bt2qPn36aMOGDQHrX3rpJaWlpSk2Nlb9+vXT5s2bw1Th6avuGAsKCqqc1+7du4exyrrLy8vTJZdcIrfbrTPPPFM33nijSkpK/Nsfe+wxpaamKi4uThdffLF27doVxmrr7mTHmZWVVeV8Dh8+PMwV180LL7ygnj17yu12KyUlRfPmzQuYCNTK+TQRbMGCBSYhIcH8/e9/Nx9++KHp2rWrGTp0aLjLCrlFixaZjIwMs3PnTv9SXFwc7rJO2+bNm80111xj4uLijCTzwQcf+Ld99NFHJiYmxjzwwAMmNzfXjBw50vzkJz8xhw4dCmPFwTvZMW7atMk4nU6Tn5/vP6979uwJY7V1179/f3PvvfeavLw8s3r1apOamur/W3zhhReMy+UyTz31lMnJyTEXXHCB6d69u6moqAhz1cE72XGuWrXKJCUlBfyd7tu3L8wV180999xjnnvuOZOXl2cef/xx06RJE/PYY48ZY+ydz4gNn4qKCpOYmGgeeOAB/7o333zTSDK7du0KX2H1YPr06ebKK68MdxkhN2PGDHP99deb9957r8oL88iRI82IESP8jw8cOGBcLpd54oknwlBp3Z3sGN955x2TkJAQxupCZ/fu3QGPn332WeN0Os2RI0dM7969zZQpU/zbtm/fbiSZtWvXWq7y9J3sOJcuXWrS09PDVFn9Gjp0qBk5cqQxxlg7nxH7ttvWrVv13XffafDgwf51F154oZxOpzZu3BjGykJv//79SkxMDHcZITd37lw9/fTT6tixY5VtWVlZAee2ZcuWSk9Pb3Dn9mTHGE3nNSUlJeBxbGysKisrdfDgQX366acB5zItLU3t2rVrcOdSqvk4peg6nz9WWVmp1q1bWz2fERs+J95jTE1N9a+Li4tTmzZttHfv3nCVVS9KSkq0fPlytWjRQj169NDChQtVXl4e7rJO2w9vi/FDBw4c0MGDBwPOrfSfP/yGdm5rOkbpP+d1586diouLU+fOnZWZmani4mKL1dUPY4yWL1+ujIwMffPNN5IUFefyx354nG63WyUlJXr33XfVrFkzpaWladq0aTp8+HC4yzwtR44c0fLly7Vx40ZNnjxZBQUFkuycz4i6pcIPHT58WE6ns8o8Q263W6WlpWGqqn7Mnj1bM2bMUFlZmd577z3dfffd+vbbb7V48eJwl1YvTvzBut3ugPVutzuqLigZMWKEzj//fDmdTuXl5WnmzJnKzc3Vhx9+qCZNmoS7vDopLy/XhAkTlJWVpffff/+k57Ih/53++DglKTMzU9ddd50qKyv18ccf6+6779YXX3yhF198MczV1k1sbKzKysrUokULPfbYY+rRo4c++OADSXbOZ8SGj8vlUmVlpY4fP66YmP+WWVpaWuUH09B169bN/++MjAxVVFRowYIFWrRo0Un/Z91QnfgPxbFjxwLWR9u5Peuss/z3p+rdu7c6deqkAQMGaMuWLerXr1+YqwteUVGRRo0apYKCAq1bt059+/ZVdna2pOg6l9UdpyR16tTJ36ZPnz7yeDwaO3asiouL1aZNm3CVW2e5ubnyer3KycnRlClTtG3bNl1xxRWS7JzPiH3bLSkpSdJ/fhFOKCsrU3FxcbXvr0eT9PR0HTlyJOBS1miSmJgol8ulwsLCgPWFhYVRfW7T09MlSbt37w5zJcHLz89XRkaG4uPjlZeXp/POO0/Sf/9Oo+Vc1nSc1WnI51OSunbtqoyMDE2cOFGLFi3SwoULrZ7PiA2f9PR0xcXFac2aNf5169evlyQNGDAgXGVZkZ2drVatWikhISHcpdQLp9Op/v37B5xbr9erzZs3a9CgQWGsrH6dGCV07tw5zJUE77rrrtPAgQP1xhtvBPwvPykpSR06dAg4l/n5+SoqKmqQ57Km46xOdna2nE5nlc9HGqKYmBgZY+TxeOydz5BeOxdit956qznzzDPN22+/bTZs2GDS0tLMpEmTwl1WyE2aNMm89dZbJjc31yxevNjExsaaBQsWhLuskCkoKKhyGfJrr71mmjRpYh5//HGTm5trrrzyStOzZ09z/PjxMFZad9Ud46JFi8yzzz5r8vLyzHPPPWeSk5PNkCFDwlhl3eTn5xtJZtWqVQHfcdm5c6c5ePCgeeihh0yzZs3MypUrzaZNm8wFF1xghg8fHu6yg3aq47zzzjvNK6+8YvLy8syyZctMq1atzPjx48NddtC8Xq8ZM2aMeeedd8xnn31mnn76aXPmmWea0aNHG2OMtfMZ0eFTWlpqxo8fb+Lj402rVq3M5MmTTWlpabjLCrkbb7zRJCQkGLfbbXr16mWeeuqpcJcUUtW9MBtjzJIlS0z79u1NXFycGTZsmCksLAxThaevumN85JFHTFJSknG5XKZLly5mxowZ5vvvvw9jlXWzfv16I6na5eGHHzaVlZVm5syZJjEx0TRv3tyMHj3aHDhwINxlB+1Uxzljxgzzk5/8xMTGxppu3bqZ+++/v0H+Z6msrMxce+21pm3btiY2Ntacc8455t577/W/tto6n9xMDgBgXcR+5gMAiF6EDwDAOsIHAGAd4QMAsI7wAQBYR/gAAKwjfAAA1hE+AADrCB8AgHWEDwDAOsIHAGAd4QMAsO7/Aw7IUgkt8fXJAAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_data(train_dataset[4564])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid shape (3, 32, 32) for image data\n",
      "torch.Size([3, 32, 32]) torch.Size([32, 32, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_data(train_dataset[8976])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "['airplane',\n 'automobile',\n 'bird',\n 'cat',\n 'deer',\n 'dog',\n 'frog',\n 'horse',\n 'ship',\n 'truck']"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.classes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "{'airplane': 0,\n 'automobile': 1,\n 'bird': 2,\n 'cat': 3,\n 'deer': 4,\n 'dog': 5,\n 'frog': 6,\n 'horse': 7,\n 'ship': 8,\n 'truck': 9}"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.class_to_idx"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def get_net():\n",
    "    resnet = torchvision.models.resnet34(pretrained=True)\n",
    "\n",
    "    # Substitute the FC output layer\n",
    "    resnet.fc = torch.nn.Linear(resnet.fc.in_features, 10)\n",
    "    torch.nn.init.xavier_uniform_(resnet.fc.weight)\n",
    "    return resnet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def train(net, train_dataloader, valid_dataloader, criterion, optimizer, scheduler=None, epochs=10, device='cpu',\n",
    "          checkpoint_epochs=10):\n",
    "    valid_loss = None\n",
    "    valid_accuracy = None\n",
    "    start = time.time()\n",
    "    print(f'Training for {epochs} epochs on {device}')\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"--> Epoch {epoch}/{epochs} |\", end=' ')\n",
    "\n",
    "        net.train()  # put network in train mode for Dropout and Batch Normalization\n",
    "        train_loss = torch.tensor(0., device=device)  # loss and accuracy tensors are on the GPU to avoid data transfers\n",
    "        train_accuracy = torch.tensor(0., device=device)\n",
    "        for X, y in train_dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            preds = net(X)\n",
    "            loss = criterion(preds, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                train_loss += loss * train_dataloader.batch_size\n",
    "                train_accuracy += (torch.argmax(preds, dim=1) == y).sum()\n",
    "\n",
    "        if valid_dataloader is not None:\n",
    "            net.eval()  # put network in train mode for Dropout and Batch Normalization\n",
    "            valid_loss = torch.tensor(0., device=device)\n",
    "            valid_accuracy = torch.tensor(0., device=device)\n",
    "            with torch.no_grad():\n",
    "                for X, y in valid_dataloader:\n",
    "                    X = X.to(device)\n",
    "                    y = y.to(device)\n",
    "                    preds = net(X)\n",
    "                    loss = criterion(preds, y)\n",
    "\n",
    "                    valid_loss += loss * valid_dataloader.batch_size\n",
    "                    valid_accuracy += (torch.argmax(preds, dim=1) == y).sum()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        print(\"Training Loss: {:.2f}\".format(train_loss / len(train_dataloader.dataset)), end='')\n",
    "\n",
    "        if valid_dataloader is not None:\n",
    "            print(\" | Validation Loss: {:.2f}\".format(valid_loss / len(valid_dataloader.dataset)),\n",
    "                  \"| Validation Accuracy: {:.2f}%\".format(100 * valid_accuracy / len(valid_dataloader.dataset)), end='')\n",
    "\n",
    "        if epoch % checkpoint_epochs == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'state_dict': net.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "            }, './checkpoint.pth.tar')\n",
    "\n",
    "        print()\n",
    "\n",
    "    end = time.time()\n",
    "    print(f'Total training time: {end - start:.1f} seconds')\n",
    "    return net\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (3): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (3): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (4): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (5): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=10, bias=True)\n)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr, weight_decay, epochs = 1e-5, 5e-4, 20\n",
    "\n",
    "net = get_net().to(device)\n",
    "net"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 20 epochs on cuda\n",
      "--> Epoch 1/20 | Training Loss: 2.01 | Validation Loss: 1.66 | Validation Accuracy: 44.50%\n",
      "--> Epoch 2/20 | Training Loss: 1.36 | Validation Loss: 1.44 | Validation Accuracy: 54.76%\n",
      "--> Epoch 3/20 | "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[39], line 9\u001B[0m\n\u001B[0;32m      5\u001B[0m params_1x \u001B[38;5;241m=\u001B[39m [param \u001B[38;5;28;01mfor\u001B[39;00m name, param \u001B[38;5;129;01min\u001B[39;00m net\u001B[38;5;241m.\u001B[39mnamed_parameters() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfc\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(name)]\n\u001B[0;32m      6\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam([{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mparams\u001B[39m\u001B[38;5;124m'\u001B[39m: params_1x}, {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mparams\u001B[39m\u001B[38;5;124m'\u001B[39m: net\u001B[38;5;241m.\u001B[39mfc\u001B[38;5;241m.\u001B[39mparameters(), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m'\u001B[39m: lr \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m10\u001B[39m}], lr\u001B[38;5;241m=\u001B[39mlr,\n\u001B[0;32m      7\u001B[0m                              weight_decay\u001B[38;5;241m=\u001B[39mweight_decay)\n\u001B[1;32m----> 9\u001B[0m net \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnet\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[37], line 20\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(net, train_dataloader, valid_dataloader, criterion, optimizer, scheduler, epochs, device, checkpoint_epochs)\u001B[0m\n\u001B[0;32m     18\u001B[0m X \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     19\u001B[0m y \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m---> 20\u001B[0m preds \u001B[38;5;241m=\u001B[39m \u001B[43mnet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(preds, y)\n\u001B[0;32m     23\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[1;32mX:\\Coding\\Github\\LearnDeepWithPyTorch\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mX:\\Coding\\Github\\LearnDeepWithPyTorch\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mX:\\Coding\\Github\\LearnDeepWithPyTorch\\venv\\lib\\site-packages\\torchvision\\models\\resnet.py:285\u001B[0m, in \u001B[0;36mResNet.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 285\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_forward_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mX:\\Coding\\Github\\LearnDeepWithPyTorch\\venv\\lib\\site-packages\\torchvision\\models\\resnet.py:275\u001B[0m, in \u001B[0;36mResNet._forward_impl\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    273\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer1(x)\n\u001B[0;32m    274\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer2(x)\n\u001B[1;32m--> 275\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayer3\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    276\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer4(x)\n\u001B[0;32m    278\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mavgpool(x)\n",
      "File \u001B[1;32mX:\\Coding\\Github\\LearnDeepWithPyTorch\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mX:\\Coding\\Github\\LearnDeepWithPyTorch\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mX:\\Coding\\Github\\LearnDeepWithPyTorch\\venv\\lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    213\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    214\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 215\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32mX:\\Coding\\Github\\LearnDeepWithPyTorch\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mX:\\Coding\\Github\\LearnDeepWithPyTorch\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mX:\\Coding\\Github\\LearnDeepWithPyTorch\\venv\\lib\\site-packages\\torchvision\\models\\resnet.py:97\u001B[0m, in \u001B[0;36mBasicBlock.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     94\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(out)\n\u001B[0;32m     96\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv2(out)\n\u001B[1;32m---> 97\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbn2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     99\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdownsample \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    100\u001B[0m     identity \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdownsample(x)\n",
      "File \u001B[1;32mX:\\Coding\\Github\\LearnDeepWithPyTorch\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mX:\\Coding\\Github\\LearnDeepWithPyTorch\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mX:\\Coding\\Github\\LearnDeepWithPyTorch\\venv\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:151\u001B[0m, in \u001B[0;36m_BatchNorm.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    148\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrack_running_stats:\n\u001B[0;32m    149\u001B[0m     \u001B[38;5;66;03m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001B[39;00m\n\u001B[0;32m    150\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_batches_tracked \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:  \u001B[38;5;66;03m# type: ignore[has-type]\u001B[39;00m\n\u001B[1;32m--> 151\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_batches_tracked\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[has-type]\u001B[39;00m\n\u001B[0;32m    152\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmomentum \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:  \u001B[38;5;66;03m# use cumulative moving average\u001B[39;00m\n\u001B[0;32m    153\u001B[0m             exponential_average_factor \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mfloat\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_batches_tracked)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Standard CrossEntropy Loss for multi-class classification problems\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# params_1x are the parameters of the network body, i.e., of all layers except the FC layers\n",
    "params_1x = [param for name, param in net.named_parameters() if 'fc' not in str(name)]\n",
    "optimizer = torch.optim.Adam([{'params': params_1x}, {'params': net.fc.parameters(), 'lr': lr * 10}], lr=lr,\n",
    "                             weight_decay=weight_decay)\n",
    "\n",
    "net = train(net, train_loader, validation_loader, criterion, optimizer, None, epochs, device)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
